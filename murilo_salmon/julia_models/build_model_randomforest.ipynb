{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65633bf6",
   "metadata": {},
   "source": [
    "Connected to Python 3.10.11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0926a65f",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fe6232-b91c-4d86-9c5b-bf8d09173549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Directly import helper function\n",
    "notebook_dir = os.getcwd()\n",
    "src_path = r\"C:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\src\"\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "from utils import add_src_to_path\n",
    "add_src_to_path()\n",
    "\n",
    "from data_split import split_time_series_by_river\n",
    "from rf_model import train_and_apply_rf_with_tuning\n",
    "from plot_predictions import plot_predictions_by_river\n",
    "from plot_predictions import plot_actual_vs_predicted\n",
    "\n",
    "# Choose from \"Bristol Bay\", \"Fraser River\" and \"Columbia River\"\n",
    "river_system = \"Fraser River\"\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))  # assumes notebook is in /notebooks\n",
    "data_path = os.path.join(project_root, 'data', 'Combined_FeatureSet_For_Model.csv')\n",
    "\n",
    "combined_df = pd.read_csv(data_path)\n",
    "# Optional: Select river system\n",
    "combined_df = combined_df[combined_df[\"System\"] == river_system]\n",
    "# Optional: Select river\n",
    "#combined_df = combined_df[combined_df[\"River\"] == \"Alagnak\"]\n",
    "\n",
    "combined_df.columns\n",
    "\n",
    "if True:\n",
    "    features_to_lag = ['Total_Returns', 'AgeClass_0.1',\n",
    "       'AgeClass_0.2', 'AgeClass_0.3', 'AgeClass_0.4', 'AgeClass_0.5',\n",
    "       'AgeClass_1.1', 'AgeClass_1.2', 'AgeClass_1.3', 'AgeClass_1.4',\n",
    "       'AgeClass_1.5', 'AgeClass_2.1', 'AgeClass_2.2', 'AgeClass_2.3',\n",
    "       'AgeClass_2.4', 'AgeClass_3.1', 'AgeClass_3.2', 'AgeClass_3.3',\n",
    "       'AgeClass_3.4', 'Total_Returns_NextYear', 'Pacea_ALPI_Anomaly',\n",
    "       'npi_mean_NovMar', 'oni_mean_DecFeb', 'npgo_mean_DecFeb',\n",
    "       'ao_mean_DecMar', 'pdo_mean_DecMar', 'pdo_mean_MaySep']\n",
    "    for feat in features_to_lag:\n",
    "        for lag in [1, 2, 3, 4, 5]:\n",
    "            combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
    "\n",
    "            # Optional: Standardize Total_Returns_NextYear\n",
    "if (False):\n",
    "    # Step 1: Compute per-river return stats\n",
    "    return_stats = combined_df.groupby('River')['Total_Returns_NextYear'].agg(\n",
    "        returns_mean='mean',\n",
    "        returns_std='std'\n",
    "    ).reset_index()\n",
    "\n",
    "    # Step 2: Merge stats temporarily for scaling\n",
    "    combined_df = combined_df.merge(return_stats, on='River', how='left')\n",
    "\n",
    "    # Step 3: Standardize Total_Returns_NextYear\n",
    "    combined_df['Total_Returns_NextYear'] = (\n",
    "        (combined_df['Total_Returns_NextYear'] - combined_df['returns_mean']) /\n",
    "        combined_df['returns_std']\n",
    "    )\n",
    "\n",
    "    # Step 4: Drop the extra columns again\n",
    "    combined_df = combined_df.drop(columns=['returns_mean', 'returns_std'])\n",
    "\n",
    "    # Optional: Keep Spawner data and remove river Ugashik and first four year (1963-1966) \n",
    "# as no data available \n",
    "if False:\n",
    "    combined_df = combined_df.dropna(subset=['total_spawners_y_minus_2_to_4'])\n",
    "    combined_df = combined_df.dropna(subset=['AgeClass_0.2_Yminus5'])\n",
    "\n",
    "missing_summary = combined_df.isnull().sum()\n",
    "missing_cols = missing_summary[missing_summary > 0]\n",
    "\n",
    "\n",
    "combined_df = combined_df.drop(columns=missing_cols.index)\n",
    "\n",
    "train_df, test_df = split_time_series_by_river(\n",
    "    combined_df,\n",
    "    time_column=\"Year\",\n",
    "    group_columns=[\"System\", \"River\"],\n",
    "    test_fraction=0.2,\n",
    "    gap_years=0  # Set to 1 if you want a 1-year gap between train and test\n",
    ")\n",
    "\n",
    "train_df[\"River_Name\"] = train_df[\"River\"] # For visualization\n",
    "test_df[\"River_Name\"] = test_df[\"River\"]\n",
    "\n",
    "train_df_encoded = pd.get_dummies(train_df, columns=[\"River\"], prefix=\"River\")\n",
    "test_df_encoded = pd.get_dummies(test_df, columns=[\"River\"], prefix=\"River\")\n",
    "\n",
    "model_list = [\"RF\", \"GBRT\", \"XGB\", \"LR\", \"PR\"]\n",
    "all_results = {}\n",
    "\n",
    "for model_name in model_list:\n",
    "    print(f\"\\n===================== {model_name} =====================\")\n",
    "    try:\n",
    "        results = train_and_apply_rf_with_tuning(\n",
    "            model=model_name,\n",
    "            train_df=train_df_encoded,\n",
    "            test_df=test_df_encoded,\n",
    "            topk_feat=10\n",
    "        )\n",
    "\n",
    "        all_results[model_name] = results  # Save results here\n",
    "\n",
    "        print(f\"‚úÖ R2 Train: {results['R2_train']:.4f}\")\n",
    "        print(f\"‚úÖ R2 Test : {results['R2']:.4f}\")\n",
    "        print(f\"üìâ MSE     : {results['MSE']:.2f}\")\n",
    "        print(f\"üìä MAPE    : {results['MAPE']:.2f}%\")\n",
    "        if results['Best_Params'] is not None:\n",
    "            print(f\"üîß Best Params: {results['Best_Params']}\")\n",
    "        else:\n",
    "            print(\"‚ÑπÔ∏è No parameter tuning applied.\")\n",
    "\n",
    "        # ‚úÖ Print per river\n",
    "        print(\"\\nüìç Metrics by River (Test):\")\n",
    "        print(results['Metrics_by_River_Test'].round(2).to_string(index=False))\n",
    "\n",
    "        print(\"\\nüìç Metrics by River (Train):\")\n",
    "        print(results['Metrics_by_River_Train'].round(2).to_string(index=False))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error while running model {model_name}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# üì¶ Collect and save all river test metrics from all models\n",
    "all_river_metrics = []\n",
    "\n",
    "for model_name, result in all_results.items():\n",
    "    df = result['Metrics_by_River_Test'].copy()\n",
    "    df.insert(0, \"Model\", model_name)  # üëà Insert model name as first column\n",
    "    all_river_metrics.append(df)\n",
    "\n",
    "# Concatenate all into one DataFrame\n",
    "final_df = pd.concat(all_river_metrics, ignore_index=True)\n",
    "\n",
    "# Save to CSV\n",
    "output_path = r\"C:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\results.csv\"\n",
    "final_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Results saved to: {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c82e4e",
   "metadata": {},
   "source": [
    "### Optional: Fit ARIMA model on residuals (only works if only one river selected so far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b2fd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:    \n",
    "    residuals = results[\"Timeline_train\"][\"Actual\"] - results[\"Timeline_train\"][\"Predicted\"]\n",
    "\n",
    "    from statsmodels.tsa.arima.model import ARIMA\n",
    "    residuals_series = pd.Series(residuals.values, index=results[\"Timeline_train\"][\"Year\"])\n",
    "    arima_model = ARIMA(residuals_series, order=(1,0,0))  # You may want to auto-tune this\n",
    "    arima_fit = arima_model.fit()\n",
    "    residual_forecast = arima_fit.forecast(steps=len(results[\"Timeline_test\"][\"Predicted\"]))\n",
    "\n",
    "    hybrid_pred = results[\"Timeline_test\"][\"Predicted\"] + residual_forecast.values\n",
    "    from sklearn.metrics import mean_squared_error, r2_score\n",
    "    r2 = r2_score(results[\"Timeline_test\"][\"Actual\"], hybrid_pred)\n",
    "    print(r2)\n",
    "\n",
    "    results[\"Timeline_test\"][\"Predicted\"] = hybrid_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80de0e3",
   "metadata": {},
   "source": [
    "### Performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719faef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"Metrics_by_System\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a492b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"Metrics_by_River\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b025528",
   "metadata": {},
   "source": [
    "### Plot predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05221a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions_by_river(results[\"Timeline_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3e8381",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions_by_river(results[\"Timeline_train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11faa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Predicted vs Actual\n",
    "plot_actual_vs_predicted(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0452feae",
   "metadata": {},
   "source": [
    "### Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d13d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_items = sorted(results[\"Feature_Importances\"].items(), key=lambda x: x[1], reverse=True)\n",
    "features, importances = zip(*sorted_items)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(features, importances, color='skyblue')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Feature Importances')\n",
    "plt.gca().invert_yaxis()  # Most important on top\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
