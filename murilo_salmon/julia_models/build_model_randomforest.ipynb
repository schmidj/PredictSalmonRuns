{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65633bf6",
   "metadata": {},
   "source": [
    "Connected to Python 3.10.11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0926a65f",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36fe6232-b91c-4d86-9c5b-bf8d09173549",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_18832\\1815902991.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_18832\\1815902991.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_18832\\1815902991.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_18832\\1815902991.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_18832\\1815902991.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_18832\\1815902991.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_18832\\1815902991.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_18832\\1815902991.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_18832\\1815902991.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_18832\\1815902991.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_18832\\1815902991.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_18832\\1815902991.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_18832\\1815902991.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_18832\\1815902991.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_18832\\1815902991.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_18832\\1815902991.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_18832\\1815902991.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_18832\\1815902991.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_18832\\1815902991.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_18832\\1815902991.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_18832\\1815902991.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_18832\\1815902991.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_18832\\1815902991.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_18832\\1815902991.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_18832\\1815902991.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_18832\\1815902991.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_18832\\1815902991.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_18832\\1815902991.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_18832\\1815902991.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_18832\\1815902991.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_18832\\1815902991.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_18832\\1815902991.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_18832\\1815902991.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_18832\\1815902991.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_18832\\1815902991.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_18832\\1815902991.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_18832\\1815902991.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_18832\\1815902991.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================== RF =====================\n",
      "Selected features:\n",
      "Index(['Total_Returns', 'AgeClass_0.2', 'AgeClass_1.1', 'AgeClass_1.2',\n",
      "       'AgeClass_2.2', 'AgeClass_2.3', 'pdo_mean_MaySep', 'River_Chilko',\n",
      "       'River_Quesnel', 'River_Raft'],\n",
      "      dtype='object')\n",
      "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "RF R2: 0.49\n",
      "RF MSE: 316008924972.28\n",
      "RF MAPE: 558.93\n",
      "✅ R2 Train: 0.8347\n",
      "✅ R2 Test : 0.4870\n",
      "📉 MSE     : 316008924972.28\n",
      "📊 MAPE    : 558.93%\n",
      "🔧 Best Params: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "\n",
      "📍 Metrics by River (Test):\n",
      " River_Name     R2          MSE    MAPE\n",
      "     Chilko   0.26 9.990875e+11  123.50\n",
      "Late Stuart -18.08 3.520742e+11  888.25\n",
      "    Quesnel   0.67 2.122437e+11 1425.84\n",
      "       Raft  -3.10 6.328142e+08  264.00\n",
      "   Stellako   0.88 1.600643e+10   93.07\n",
      "\n",
      "📍 Metrics by River (Train):\n",
      " River_Name     R2          MSE   MAPE\n",
      "     Chilko   0.79 2.381062e+11  40.51\n",
      "Late Stuart   0.86 1.246500e+11 322.57\n",
      "    Quesnel   0.81 1.283544e+12 881.48\n",
      "       Raft -34.90 2.654532e+10 261.43\n",
      "   Stellako   0.64 3.790975e+10  42.70\n",
      "\n",
      "===================== GBRT =====================\n",
      "Selected features:\n",
      "Index(['Total_Returns', 'AgeClass_0.2', 'AgeClass_1.1', 'AgeClass_1.2',\n",
      "       'AgeClass_2.2', 'AgeClass_2.3', 'pdo_mean_MaySep', 'River_Chilko',\n",
      "       'River_Quesnel', 'River_Raft'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:145: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  system_metrics_test = results_df.groupby(\"System\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:149: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  river_metrics_test = results_df.groupby(\"River_Name\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:153: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  system_metrics_train = train_results_df.groupby(\"System\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:157: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  river_metrics_train = train_results_df.groupby(\"River_Name\", group_keys=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.05, 'max_depth': 5, 'max_iter': 200, 'min_samples_leaf': 1}\n",
      "GBRT R2: 0.23\n",
      "GBRT MSE: 472923345222.29\n",
      "GBRT MAPE: 682.68\n",
      "✅ R2 Train: 0.9975\n",
      "✅ R2 Test : 0.2323\n",
      "📉 MSE     : 472923345222.29\n",
      "📊 MAPE    : 682.68%\n",
      "🔧 Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'max_iter': 200, 'min_samples_leaf': 1}\n",
      "\n",
      "📍 Metrics by River (Test):\n",
      " River_Name     R2          MSE    MAPE\n",
      "     Chilko   0.20 1.085816e+12  133.90\n",
      "Late Stuart -42.32 7.993017e+11  718.74\n",
      "    Quesnel   0.30 4.524269e+11 1806.26\n",
      "       Raft -63.75 1.000281e+10  678.59\n",
      "   Stellako   0.87 1.706957e+10   75.90\n",
      "\n",
      "📍 Metrics by River (Train):\n",
      " River_Name    R2          MSE   MAPE\n",
      "     Chilko  1.00 4.511670e+09   7.61\n",
      "Late Stuart  0.99 1.010279e+10 367.11\n",
      "    Quesnel  1.00 2.859021e+09 596.54\n",
      "       Raft -0.17 8.677259e+08 152.99\n",
      "   Stellako  0.93 7.394838e+09  23.02\n",
      "\n",
      "===================== XGB =====================\n",
      "Selected features:\n",
      "Index(['Total_Returns', 'AgeClass_0.2', 'AgeClass_1.1', 'AgeClass_1.2',\n",
      "       'AgeClass_2.2', 'AgeClass_2.3', 'pdo_mean_MaySep', 'River_Chilko',\n",
      "       'River_Quesnel', 'River_Raft'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:145: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  system_metrics_test = results_df.groupby(\"System\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:149: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  river_metrics_test = results_df.groupby(\"River_Name\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:153: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  system_metrics_train = train_results_df.groupby(\"System\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:157: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  river_metrics_train = train_results_df.groupby(\"River_Name\", group_keys=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.05, 'max_depth': 6, 'n_estimators': 100}\n",
      "XGB R2: 0.12\n",
      "XGB MSE: 541215021291.21\n",
      "XGB MAPE: 608.66\n",
      "✅ R2 Train: 0.9840\n",
      "✅ R2 Test : 0.1215\n",
      "📉 MSE     : 541215021291.21\n",
      "📊 MAPE    : 608.66%\n",
      "🔧 Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'n_estimators': 100}\n",
      "\n",
      "📍 Metrics by River (Test):\n",
      " River_Name     R2          MSE    MAPE\n",
      "     Chilko   0.41 8.006628e+11  129.30\n",
      "Late Stuart -75.49 1.411350e+12  913.31\n",
      "    Quesnel   0.28 4.687033e+11 1311.43\n",
      "       Raft -13.65 2.263041e+09  583.76\n",
      "   Stellako   0.82 2.309588e+10  105.48\n",
      "\n",
      "📍 Metrics by River (Train):\n",
      " River_Name    R2          MSE    MAPE\n",
      "     Chilko  0.98 1.991929e+10   17.87\n",
      "Late Stuart  0.92 6.919664e+10  589.35\n",
      "    Quesnel  0.99 4.357125e+10 1545.71\n",
      "       Raft -1.11 1.560676e+09  288.36\n",
      "   Stellako  0.70 3.082048e+10   44.26\n",
      "\n",
      "===================== LR =====================\n",
      "Selected features:\n",
      "Index(['Total_Returns', 'AgeClass_0.2', 'AgeClass_1.1', 'AgeClass_1.2',\n",
      "       'AgeClass_2.2', 'AgeClass_2.3', 'pdo_mean_MaySep', 'River_Chilko',\n",
      "       'River_Quesnel', 'River_Raft'],\n",
      "      dtype='object')\n",
      "Best Parameters: {'fit_intercept': False, 'positive': False}\n",
      "LR R2: 0.32\n",
      "LR MSE: 420987448442.98\n",
      "LR MAPE: 1470.70\n",
      "✅ R2 Train: 0.4048\n",
      "✅ R2 Test : 0.3166\n",
      "📉 MSE     : 420987448442.98\n",
      "📊 MAPE    : 1470.70%\n",
      "🔧 Best Params: {'fit_intercept': False, 'positive': False}\n",
      "\n",
      "📍 Metrics by River (Test):\n",
      " River_Name      R2          MSE    MAPE\n",
      "     Chilko    0.05 1.284324e+12   93.93\n",
      "Late Stuart   -1.91 5.362503e+10  192.20\n",
      "    Quesnel   -0.04 6.756428e+11 5849.11\n",
      "       Raft -113.16 1.763528e+10 1100.44\n",
      "   Stellako    0.43 7.370990e+10  117.81\n",
      "\n",
      "📍 Metrics by River (Train):\n",
      " River_Name      R2          MSE     MAPE\n",
      "     Chilko    0.11 9.869957e+11    71.95\n",
      "Late Stuart    0.01 8.865206e+11   341.99\n",
      "    Quesnel    0.41 3.994548e+12 14869.58\n",
      "       Raft -134.12 9.990473e+10   588.39\n",
      "   Stellako   -0.83 1.913065e+11    76.08\n",
      "\n",
      "===================== PR =====================\n",
      "Selected features:\n",
      "Index(['Total_Returns', 'AgeClass_0.2', 'AgeClass_1.1', 'AgeClass_1.2',\n",
      "       'AgeClass_2.2', 'AgeClass_2.3', 'pdo_mean_MaySep', 'River_Chilko',\n",
      "       'River_Quesnel', 'River_Raft'],\n",
      "      dtype='object')\n",
      "No parameter tuning for this model.\n",
      "PR R2: 0.14\n",
      "PR MSE: 529254599014.91\n",
      "PR MAPE: 1375.06\n",
      "✅ R2 Train: 0.7678\n",
      "✅ R2 Test : 0.1409\n",
      "📉 MSE     : 529254599014.91\n",
      "📊 MAPE    : 1375.06%\n",
      "ℹ️ No parameter tuning applied.\n",
      "\n",
      "📍 Metrics by River (Test):\n",
      " River_Name      R2          MSE    MAPE\n",
      "     Chilko   -0.14 1.545249e+12  181.58\n",
      "Late Stuart   -3.77 8.801869e+10  690.31\n",
      "    Quesnel    0.11 5.815350e+11 3846.09\n",
      "       Raft -255.84 3.967524e+10 1942.60\n",
      "   Stellako   -2.03 3.917952e+11  214.70\n",
      "\n",
      "📍 Metrics by River (Train):\n",
      " River_Name      R2          MSE    MAPE\n",
      "     Chilko    0.59 4.561145e+11   60.53\n",
      "Late Stuart    0.69 2.756863e+11 1038.98\n",
      "    Quesnel    0.78 1.465782e+12 8233.90\n",
      "       Raft -193.30 1.436557e+11 1243.27\n",
      "   Stellako    0.40 6.211542e+10   70.21\n",
      "\n",
      "✅ Final metrics with system saved to:\n",
      "C:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\results.csv\n",
      "\n",
      "✅ Final metrics with system saved to:\n",
      "C:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\results.csv\n",
      "\n",
      "✅ Final metrics with system saved to:\n",
      "C:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\results.csv\n",
      "\n",
      "✅ Final metrics with system saved to:\n",
      "C:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\results.csv\n",
      "\n",
      "✅ Final metrics with system saved to:\n",
      "C:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:145: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  system_metrics_test = results_df.groupby(\"System\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:149: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  river_metrics_test = results_df.groupby(\"River_Name\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:153: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  system_metrics_train = train_results_df.groupby(\"System\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:157: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  river_metrics_train = train_results_df.groupby(\"River_Name\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:145: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  system_metrics_test = results_df.groupby(\"System\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:149: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  river_metrics_test = results_df.groupby(\"River_Name\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:153: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  system_metrics_train = train_results_df.groupby(\"System\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:157: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  river_metrics_train = train_results_df.groupby(\"River_Name\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:145: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  system_metrics_test = results_df.groupby(\"System\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:149: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  river_metrics_test = results_df.groupby(\"River_Name\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:153: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  system_metrics_train = train_results_df.groupby(\"System\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:157: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  river_metrics_train = train_results_df.groupby(\"River_Name\", group_keys=False).apply(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Directly import helper function\n",
    "notebook_dir = os.getcwd()\n",
    "src_path = r\"C:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\src\"\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "from utils import add_src_to_path\n",
    "add_src_to_path()\n",
    "\n",
    "from data_split import split_time_series_by_river\n",
    "from rf_model import train_and_apply_rf_with_tuning\n",
    "from plot_predictions import plot_predictions_by_river\n",
    "from plot_predictions import plot_actual_vs_predicted\n",
    "\n",
    "# Choose from \"Bristol Bay\", \"Fraser River\" and \"Columbia River\"\n",
    "river_system = \"Fraser River\"\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))  # assumes notebook is in /notebooks\n",
    "data_path = os.path.join(project_root, 'data', 'Combined_FeatureSet_For_Model.csv')\n",
    "\n",
    "combined_df = pd.read_csv(data_path)\n",
    "# Optional: Select river system\n",
    "combined_df = combined_df[combined_df[\"System\"] == river_system]\n",
    "# Optional: Select river\n",
    "#combined_df = combined_df[combined_df[\"River\"] == \"Alagnak\"]\n",
    "\n",
    "combined_df.columns\n",
    "\n",
    "if True:\n",
    "    features_to_lag = ['Total_Returns', 'AgeClass_0.1',\n",
    "       'AgeClass_0.2', 'AgeClass_0.3', 'AgeClass_0.4', 'AgeClass_0.5',\n",
    "       'AgeClass_1.1', 'AgeClass_1.2', 'AgeClass_1.3', 'AgeClass_1.4',\n",
    "       'AgeClass_1.5', 'AgeClass_2.1', 'AgeClass_2.2', 'AgeClass_2.3',\n",
    "       'AgeClass_2.4', 'AgeClass_3.1', 'AgeClass_3.2', 'AgeClass_3.3',\n",
    "       'AgeClass_3.4', 'Total_Returns_NextYear', 'Pacea_ALPI_Anomaly',\n",
    "       'npi_mean_NovMar', 'oni_mean_DecFeb', 'npgo_mean_DecFeb',\n",
    "       'ao_mean_DecMar', 'pdo_mean_DecMar', 'pdo_mean_MaySep']\n",
    "    for feat in features_to_lag:\n",
    "        for lag in [1, 2, 3, 4, 5]:\n",
    "            combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
    "\n",
    "            # Optional: Standardize Total_Returns_NextYear\n",
    "if (False):\n",
    "    # Step 1: Compute per-river return stats\n",
    "    return_stats = combined_df.groupby('River')['Total_Returns_NextYear'].agg(\n",
    "        returns_mean='mean',\n",
    "        returns_std='std'\n",
    "    ).reset_index()\n",
    "\n",
    "    # Step 2: Merge stats temporarily for scaling\n",
    "    combined_df = combined_df.merge(return_stats, on='River', how='left')\n",
    "\n",
    "    # Step 3: Standardize Total_Returns_NextYear\n",
    "    combined_df['Total_Returns_NextYear'] = (\n",
    "        (combined_df['Total_Returns_NextYear'] - combined_df['returns_mean']) /\n",
    "        combined_df['returns_std']\n",
    "    )\n",
    "\n",
    "    # Step 4: Drop the extra columns again\n",
    "    combined_df = combined_df.drop(columns=['returns_mean', 'returns_std'])\n",
    "\n",
    "    # Optional: Keep Spawner data and remove river Ugashik and first four year (1963-1966) \n",
    "# as no data available \n",
    "if False:\n",
    "    combined_df = combined_df.dropna(subset=['total_spawners_y_minus_2_to_4'])\n",
    "    combined_df = combined_df.dropna(subset=['AgeClass_0.2_Yminus5'])\n",
    "\n",
    "missing_summary = combined_df.isnull().sum()\n",
    "missing_cols = missing_summary[missing_summary > 0]\n",
    "\n",
    "\n",
    "combined_df = combined_df.drop(columns=missing_cols.index)\n",
    "\n",
    "train_df, test_df = split_time_series_by_river(\n",
    "    combined_df,\n",
    "    time_column=\"Year\",\n",
    "    group_columns=[\"System\", \"River\"],\n",
    "    test_fraction=0.2,\n",
    "    gap_years=0  # Set to 1 if you want a 1-year gap between train and test\n",
    ")\n",
    "\n",
    "train_df[\"River_Name\"] = train_df[\"River\"] # For visualization\n",
    "test_df[\"River_Name\"] = test_df[\"River\"]\n",
    "\n",
    "train_df_encoded = pd.get_dummies(train_df, columns=[\"River\"], prefix=\"River\")\n",
    "test_df_encoded = pd.get_dummies(test_df, columns=[\"River\"], prefix=\"River\")\n",
    "\n",
    "model_list = [\"RF\", \"GBRT\", \"XGB\", \"LR\", \"PR\"]\n",
    "all_results = {}\n",
    "\n",
    "for model_name in model_list:\n",
    "    print(f\"\\n===================== {model_name} =====================\")\n",
    "    try:\n",
    "        results = train_and_apply_rf_with_tuning(\n",
    "            model=model_name,\n",
    "            train_df=train_df_encoded,\n",
    "            test_df=test_df_encoded,\n",
    "            topk_feat=10\n",
    "        )\n",
    "\n",
    "        all_results[model_name] = results  # Save results here\n",
    "\n",
    "        print(f\"✅ R2 Train: {results['R2_train']:.4f}\")\n",
    "        print(f\"✅ R2 Test : {results['R2']:.4f}\")\n",
    "        print(f\"📉 MSE     : {results['MSE']:.2f}\")\n",
    "        print(f\"📊 MAPE    : {results['MAPE']:.2f}%\")\n",
    "        if results['Best_Params'] is not None:\n",
    "            print(f\"🔧 Best Params: {results['Best_Params']}\")\n",
    "        else:\n",
    "            print(\"ℹ️ No parameter tuning applied.\")\n",
    "\n",
    "        # ✅ Print per river\n",
    "        print(\"\\n📍 Metrics by River (Test):\")\n",
    "        print(results['Metrics_by_River_Test'].round(2).to_string(index=False))\n",
    "\n",
    "        print(\"\\n📍 Metrics by River (Train):\")\n",
    "        print(results['Metrics_by_River_Train'].round(2).to_string(index=False))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error while running model {model_name}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "merged_metrics = []\n",
    "\n",
    "for model_name, result in all_results.items():\n",
    "    test_df = result['Metrics_by_River_Test'].copy()\n",
    "    train_df = result['Metrics_by_River_Train'].copy()\n",
    "\n",
    "    # Rename metric columns\n",
    "    test_df = test_df.rename(columns={\"R2\": \"R2_Test\", \"MSE\": \"MSE_Test\", \"MAPE\": \"MAPE_Test\"})\n",
    "    train_df = train_df.rename(columns={\"R2\": \"R2_Train\", \"MSE\": \"MSE_Train\", \"MAPE\": \"MAPE_Train\"})\n",
    "\n",
    "    # Merge test and train on River_Name\n",
    "    merged_df = pd.merge(test_df, train_df, on=\"River_Name\", how=\"outer\")\n",
    "\n",
    "    # Add model name\n",
    "    merged_df.insert(0, \"Model\", model_name)\n",
    "\n",
    "    # Optional: Add System info (lookup from train_df or test_df)\n",
    "    # You only need to do this once, so use one of the full dataframes\n",
    "    river_system_map = pd.concat([train_df, test_df], ignore_index=True)[[\"River_Name\"]].drop_duplicates()\n",
    "    river_system_lookup = pd.concat([train_df_encoded, test_df_encoded], ignore_index=True)[[\"River_Name\", \"System\"]].drop_duplicates()\n",
    "\n",
    "    merged_df = pd.merge(merged_df, river_system_lookup, on=\"River_Name\", how=\"left\")\n",
    "\n",
    "    merged_metrics.append(merged_df)\n",
    "\n",
    "\n",
    "    final_df = pd.concat(merged_metrics, ignore_index=True)\n",
    "\n",
    "    output_path = r\"C:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\results.csv\"\n",
    "    final_df.to_csv(output_path, index=False)\n",
    "\n",
    "    print(f\"\\n✅ Final metrics with system saved to:\\n{output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c82e4e",
   "metadata": {},
   "source": [
    "### Optional: Fit ARIMA model on residuals (only works if only one river selected so far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b2fd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:    \n",
    "    residuals = results[\"Timeline_train\"][\"Actual\"] - results[\"Timeline_train\"][\"Predicted\"]\n",
    "\n",
    "    from statsmodels.tsa.arima.model import ARIMA\n",
    "    residuals_series = pd.Series(residuals.values, index=results[\"Timeline_train\"][\"Year\"])\n",
    "    arima_model = ARIMA(residuals_series, order=(1,0,0))  # You may want to auto-tune this\n",
    "    arima_fit = arima_model.fit()\n",
    "    residual_forecast = arima_fit.forecast(steps=len(results[\"Timeline_test\"][\"Predicted\"]))\n",
    "\n",
    "    hybrid_pred = results[\"Timeline_test\"][\"Predicted\"] + residual_forecast.values\n",
    "    from sklearn.metrics import mean_squared_error, r2_score\n",
    "    r2 = r2_score(results[\"Timeline_test\"][\"Actual\"], hybrid_pred)\n",
    "    print(r2)\n",
    "\n",
    "    results[\"Timeline_test\"][\"Predicted\"] = hybrid_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80de0e3",
   "metadata": {},
   "source": [
    "### Performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719faef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"Metrics_by_System\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a492b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"Metrics_by_River\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b025528",
   "metadata": {},
   "source": [
    "### Plot predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05221a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions_by_river(results[\"Timeline_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3e8381",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions_by_river(results[\"Timeline_train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11faa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Predicted vs Actual\n",
    "plot_actual_vs_predicted(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0452feae",
   "metadata": {},
   "source": [
    "### Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d13d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_items = sorted(results[\"Feature_Importances\"].items(), key=lambda x: x[1], reverse=True)\n",
    "features, importances = zip(*sorted_items)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(features, importances, color='skyblue')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Feature Importances')\n",
    "plt.gca().invert_yaxis()  # Most important on top\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
