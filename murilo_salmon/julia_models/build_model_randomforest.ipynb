{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65633bf6",
   "metadata": {},
   "source": [
    "Connected to Python 3.10.11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0926a65f",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e15668e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36fe6232-b91c-4d86-9c5b-bf8d09173549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§ª Running: Fraser River | TopK=6 | ExtraFeat=True | ARIMA=True\n",
      "Selected features:\n",
      "Index(['Total_Returns', 'AgeClass_0.2', 'AgeClass_1.1', 'River_Chilko',\n",
      "       'River_Quesnel', 'River_Raft'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "RF R2: 0.41\n",
      "RF MSE: 365025695484.21\n",
      "RF MAPE: 477.37\n",
      "Selected features:\n",
      "Index(['Total_Returns', 'AgeClass_0.2', 'AgeClass_1.1', 'River_Chilko',\n",
      "       'River_Quesnel', 'River_Raft'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:145: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  system_metrics_test = results_df.groupby(\"System\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:149: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  river_metrics_test = results_df.groupby(\"River_Name\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:153: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  system_metrics_train = train_results_df.groupby(\"System\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:157: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  river_metrics_train = train_results_df.groupby(\"River_Name\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:102: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  metrics_by_river_test = grouped.apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.05, 'max_depth': 5, 'max_iter': 200, 'min_samples_leaf': 1}\n",
      "GBRT R2: 0.21\n",
      "GBRT MSE: 486627008236.27\n",
      "GBRT MAPE: 442.80\n",
      "Selected features:\n",
      "Index(['Total_Returns', 'AgeClass_0.2', 'AgeClass_1.1', 'River_Chilko',\n",
      "       'River_Quesnel', 'River_Raft'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:145: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  system_metrics_test = results_df.groupby(\"System\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:149: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  river_metrics_test = results_df.groupby(\"River_Name\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:153: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  system_metrics_train = train_results_df.groupby(\"System\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:157: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  river_metrics_train = train_results_df.groupby(\"River_Name\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:102: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  metrics_by_river_test = grouped.apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200}\n",
      "XGB R2: 0.43\n",
      "XGB MSE: 354220998416.79\n",
      "XGB MAPE: 382.47\n",
      "Selected features:\n",
      "Index(['Total_Returns', 'AgeClass_0.2', 'AgeClass_1.1', 'River_Chilko',\n",
      "       'River_Quesnel', 'River_Raft'],\n",
      "      dtype='object')\n",
      "Best Parameters: {'fit_intercept': True, 'positive': False}\n",
      "LR R2: 0.34\n",
      "LR MSE: 408886514095.51\n",
      "LR MAPE: 1753.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:145: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  system_metrics_test = results_df.groupby(\"System\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:149: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  river_metrics_test = results_df.groupby(\"River_Name\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:153: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  system_metrics_train = train_results_df.groupby(\"System\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:157: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  river_metrics_train = train_results_df.groupby(\"River_Name\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:102: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  metrics_by_river_test = grouped.apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:145: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  system_metrics_test = results_df.groupby(\"System\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:149: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  river_metrics_test = results_df.groupby(\"River_Name\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:153: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  system_metrics_train = train_results_df.groupby(\"System\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:157: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  river_metrics_train = train_results_df.groupby(\"River_Name\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:102: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  metrics_by_river_test = grouped.apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features:\n",
      "Index(['Total_Returns', 'AgeClass_0.2', 'AgeClass_1.1', 'River_Chilko',\n",
      "       'River_Quesnel', 'River_Raft'],\n",
      "      dtype='object')\n",
      "No parameter tuning for this model.\n",
      "PR R2: 0.16\n",
      "PR MSE: 518184352425.38\n",
      "PR MAPE: 1269.42\n",
      "\n",
      "ðŸ§ª Running: Fraser River | TopK=6 | ExtraFeat=True | ARIMA=False\n",
      "Selected features:\n",
      "Index(['Total_Returns', 'AgeClass_0.2', 'AgeClass_1.1', 'River_Chilko',\n",
      "       'River_Quesnel', 'River_Raft'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:145: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  system_metrics_test = results_df.groupby(\"System\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:149: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  river_metrics_test = results_df.groupby(\"River_Name\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:153: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  system_metrics_train = train_results_df.groupby(\"System\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:157: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  river_metrics_train = train_results_df.groupby(\"River_Name\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:102: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  metrics_by_river_test = grouped.apply(\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "RF R2: 0.41\n",
      "RF MSE: 365025695484.21\n",
      "RF MAPE: 477.37\n",
      "Selected features:\n",
      "Index(['Total_Returns', 'AgeClass_0.2', 'AgeClass_1.1', 'River_Chilko',\n",
      "       'River_Quesnel', 'River_Raft'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:145: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  system_metrics_test = results_df.groupby(\"System\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:149: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  river_metrics_test = results_df.groupby(\"River_Name\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:153: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  system_metrics_train = train_results_df.groupby(\"System\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:157: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  river_metrics_train = train_results_df.groupby(\"River_Name\", group_keys=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.05, 'max_depth': 5, 'max_iter': 200, 'min_samples_leaf': 1}\n",
      "GBRT R2: 0.21\n",
      "GBRT MSE: 486627008236.27\n",
      "GBRT MAPE: 442.80\n",
      "Selected features:\n",
      "Index(['Total_Returns', 'AgeClass_0.2', 'AgeClass_1.1', 'River_Chilko',\n",
      "       'River_Quesnel', 'River_Raft'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:145: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  system_metrics_test = results_df.groupby(\"System\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:149: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  river_metrics_test = results_df.groupby(\"River_Name\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:153: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  system_metrics_train = train_results_df.groupby(\"System\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:157: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  river_metrics_train = train_results_df.groupby(\"River_Name\", group_keys=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200}\n",
      "XGB R2: 0.43\n",
      "XGB MSE: 354220998416.79\n",
      "XGB MAPE: 382.47\n",
      "Selected features:\n",
      "Index(['Total_Returns', 'AgeClass_0.2', 'AgeClass_1.1', 'River_Chilko',\n",
      "       'River_Quesnel', 'River_Raft'],\n",
      "      dtype='object')\n",
      "Best Parameters: {'fit_intercept': True, 'positive': False}\n",
      "LR R2: 0.34\n",
      "LR MSE: 408886514095.51\n",
      "LR MAPE: 1753.96\n",
      "Selected features:\n",
      "Index(['Total_Returns', 'AgeClass_0.2', 'AgeClass_1.1', 'River_Chilko',\n",
      "       'River_Quesnel', 'River_Raft'],\n",
      "      dtype='object')\n",
      "No parameter tuning for this model.\n",
      "PR R2: 0.16\n",
      "PR MSE: 518184352425.38\n",
      "PR MAPE: 1269.42\n",
      "\n",
      "ðŸ§ª Running: Fraser River | TopK=6 | ExtraFeat=False | ARIMA=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:145: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  system_metrics_test = results_df.groupby(\"System\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:149: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  river_metrics_test = results_df.groupby(\"River_Name\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:153: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  system_metrics_train = train_results_df.groupby(\"System\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:157: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  river_metrics_train = train_results_df.groupby(\"River_Name\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:145: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  system_metrics_test = results_df.groupby(\"System\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:149: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  river_metrics_test = results_df.groupby(\"River_Name\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:153: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  system_metrics_train = train_results_df.groupby(\"System\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:157: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  river_metrics_train = train_results_df.groupby(\"River_Name\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:145: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  system_metrics_test = results_df.groupby(\"System\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:149: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  river_metrics_test = results_df.groupby(\"River_Name\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:153: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  system_metrics_train = train_results_df.groupby(\"System\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:157: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  river_metrics_train = train_results_df.groupby(\"River_Name\", group_keys=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features:\n",
      "Index(['Total_Returns', 'AgeClass_0.2', 'AgeClass_1.1', 'River_Chilko',\n",
      "       'River_Quesnel', 'River_Raft'],\n",
      "      dtype='object')\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "RF R2: 0.41\n",
      "RF MSE: 365025695484.21\n",
      "RF MAPE: 477.37\n",
      "Selected features:\n",
      "Index(['Total_Returns', 'AgeClass_0.2', 'AgeClass_1.1', 'River_Chilko',\n",
      "       'River_Quesnel', 'River_Raft'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:145: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  system_metrics_test = results_df.groupby(\"System\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:149: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  river_metrics_test = results_df.groupby(\"River_Name\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:153: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  system_metrics_train = train_results_df.groupby(\"System\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:157: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  river_metrics_train = train_results_df.groupby(\"River_Name\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:102: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  metrics_by_river_test = grouped.apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.05, 'max_depth': 5, 'max_iter': 200, 'min_samples_leaf': 1}\n",
      "GBRT R2: 0.21\n",
      "GBRT MSE: 486627008236.27\n",
      "GBRT MAPE: 442.80\n",
      "Selected features:\n",
      "Index(['Total_Returns', 'AgeClass_0.2', 'AgeClass_1.1', 'River_Chilko',\n",
      "       'River_Quesnel', 'River_Raft'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:145: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  system_metrics_test = results_df.groupby(\"System\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:149: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  river_metrics_test = results_df.groupby(\"River_Name\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:153: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  system_metrics_train = train_results_df.groupby(\"System\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:157: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  river_metrics_train = train_results_df.groupby(\"River_Name\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:102: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  metrics_by_river_test = grouped.apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200}\n",
      "XGB R2: 0.43\n",
      "XGB MSE: 354220998416.79\n",
      "XGB MAPE: 382.47\n",
      "Selected features:\n",
      "Index(['Total_Returns', 'AgeClass_0.2', 'AgeClass_1.1', 'River_Chilko',\n",
      "       'River_Quesnel', 'River_Raft'],\n",
      "      dtype='object')\n",
      "Best Parameters: {'fit_intercept': True, 'positive': False}\n",
      "LR R2: 0.34\n",
      "LR MSE: 408886514095.51\n",
      "LR MAPE: 1753.96\n",
      "Selected features:\n",
      "Index(['Total_Returns', 'AgeClass_0.2', 'AgeClass_1.1', 'River_Chilko',\n",
      "       'River_Quesnel', 'River_Raft'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:145: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  system_metrics_test = results_df.groupby(\"System\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:149: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  river_metrics_test = results_df.groupby(\"River_Name\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:153: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  system_metrics_train = train_results_df.groupby(\"System\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:157: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  river_metrics_train = train_results_df.groupby(\"River_Name\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:102: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  metrics_by_river_test = grouped.apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:145: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  system_metrics_test = results_df.groupby(\"System\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:149: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  river_metrics_test = results_df.groupby(\"River_Name\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:153: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  system_metrics_train = train_results_df.groupby(\"System\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:157: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  river_metrics_train = train_results_df.groupby(\"River_Name\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:102: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  metrics_by_river_test = grouped.apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:145: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  system_metrics_test = results_df.groupby(\"System\", group_keys=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No parameter tuning for this model.\n",
      "PR R2: 0.16\n",
      "PR MSE: 518184352425.38\n",
      "PR MAPE: 1269.42\n",
      "\n",
      "ðŸ§ª Running: Fraser River | TopK=6 | ExtraFeat=False | ARIMA=False\n",
      "Selected features:\n",
      "Index(['Total_Returns', 'AgeClass_0.2', 'AgeClass_1.1', 'River_Chilko',\n",
      "       'River_Quesnel', 'River_Raft'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:149: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  river_metrics_test = results_df.groupby(\"River_Name\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:153: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  system_metrics_train = train_results_df.groupby(\"System\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:157: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  river_metrics_train = train_results_df.groupby(\"River_Name\", group_keys=False).apply(\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "C:\\Users\\MuriloFarias\\AppData\\Local\\Temp\\ipykernel_29848\\619836447.py:102: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  metrics_by_river_test = grouped.apply(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 75\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m model_list:\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 75\u001b[0m         results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_apply_rf_with_tuning\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_df_encoded\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtest_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_df_encoded\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtopk_feat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_k_features\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m         \u001b[38;5;66;03m# âœ… Apply ARIMA correction if selected\u001b[39;00m\n\u001b[0;32m     83\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m use_arima_on_top:\n",
      "File \u001b[1;32mc:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\rf_model.py:63\u001b[0m, in \u001b[0;36mtrain_and_apply_rf_with_tuning\u001b[1;34m(model, train_df, test_df, topk_feat, target_col)\u001b[0m\n\u001b[0;32m     61\u001b[0m     base_model \u001b[38;5;241m=\u001b[39m RandomForestRegressor(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     62\u001b[0m     grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(base_model, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 63\u001b[0m     \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (model \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGBRT\u001b[39m\u001b[38;5;124m\"\u001b[39m): \u001b[38;5;66;03m#GradientBoostingRegressor\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     67\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.05\u001b[39m, \u001b[38;5;241m0.1\u001b[39m],\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m],\n\u001b[0;32m     69\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_samples_leaf\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m     70\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_iter\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m]\n\u001b[0;32m     71\u001b[0m     }\n",
      "File \u001b[1;32mc:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1363\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1356\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1358\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1359\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1360\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1361\u001b[0m     )\n\u001b[0;32m   1362\u001b[0m ):\n\u001b[1;32m-> 1363\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1051\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1045\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1046\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1047\u001b[0m     )\n\u001b[0;32m   1049\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1051\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1605\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1603\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1604\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1605\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:997\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    990\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    993\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    994\u001b[0m         )\n\u001b[0;32m    995\u001b[0m     )\n\u001b[1;32m--> 997\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    998\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    999\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1000\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1001\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1002\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1003\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1004\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1005\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1007\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1008\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1009\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1012\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1016\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1017\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1018\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1019\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1020\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     73\u001b[0m warning_filters \u001b[38;5;241m=\u001b[39m warnings\u001b[38;5;241m.\u001b[39mfilters\n\u001b[0;32m     74\u001b[0m iterable_with_config_and_warning_filters \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     75\u001b[0m     (\n\u001b[0;32m     76\u001b[0m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     81\u001b[0m )\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:2072\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2066\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2067\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2068\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2069\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2070\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1682\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1679\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1681\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1682\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1684\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1685\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1687\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1688\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\MuriloFarias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1800\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_ordered:\n\u001b[0;32m   1790\u001b[0m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[0;32m   1791\u001b[0m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1795\u001b[0m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[0;32m   1796\u001b[0m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[0;32m   1797\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1798\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING\n\u001b[0;32m   1799\u001b[0m     ):\n\u001b[1;32m-> 1800\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1801\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1803\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1804\u001b[0m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[0;32m   1805\u001b[0m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1811\u001b[0m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[0;32m   1812\u001b[0m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Set paths\n",
    "notebook_dir = os.getcwd()\n",
    "src_path = r\"C:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\src\"\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "from utils import add_src_to_path\n",
    "add_src_to_path()\n",
    "\n",
    "from data_split import split_time_series_by_river\n",
    "from rf_model import train_and_apply_rf_with_tuning\n",
    "from plot_predictions import plot_predictions_by_river\n",
    "from plot_predictions import plot_actual_vs_predicted\n",
    "\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "# Experiment parameters\n",
    "river_systems = [\"Fraser River\", \"Bristol Bay\", \"Columbia River\"]\n",
    "top_k_options = [6, 10, 20]\n",
    "add_feat_options = [True, False]\n",
    "arima_options = [True, False]\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "data_path = os.path.join(project_root, 'data', 'Combined_FeatureSet_For_Model.csv')\n",
    "\n",
    "model_list = [\"RF\", \"GBRT\", \"XGB\", \"LR\", \"PR\"]\n",
    "all_experiments = []\n",
    "\n",
    "for river_system, top_k_features, add_additional_features, use_arima_on_top in itertools.product(\n",
    "    river_systems, top_k_options, add_feat_options, arima_options\n",
    "):\n",
    "    print(f\"\\nðŸ§ª Running: {river_system} | TopK={top_k_features} | ExtraFeat={add_additional_features} | ARIMA={use_arima_on_top}\")\n",
    "\n",
    "    combined_df = pd.read_csv(data_path)\n",
    "    combined_df = combined_df[combined_df[\"System\"] == river_system]\n",
    "\n",
    "    if add_additional_features:\n",
    "        features_to_lag = [\n",
    "            'Total_Returns', 'AgeClass_0.1', 'AgeClass_0.2', 'AgeClass_0.3', 'AgeClass_0.4', 'AgeClass_0.5',\n",
    "            'AgeClass_1.1', 'AgeClass_1.2', 'AgeClass_1.3', 'AgeClass_1.4', 'AgeClass_1.5',\n",
    "            'AgeClass_2.1', 'AgeClass_2.2', 'AgeClass_2.3', 'AgeClass_2.4',\n",
    "            'AgeClass_3.1', 'AgeClass_3.2', 'AgeClass_3.3', 'AgeClass_3.4',\n",
    "            'Total_Returns_NextYear', 'Pacea_ALPI_Anomaly', 'npi_mean_NovMar', 'oni_mean_DecFeb',\n",
    "            'npgo_mean_DecFeb', 'ao_mean_DecMar', 'pdo_mean_DecMar', 'pdo_mean_MaySep'\n",
    "        ]\n",
    "        for feat in features_to_lag:\n",
    "            for lag in [1, 2, 3, 4, 5]:\n",
    "                combined_df[f'{feat}_Yminus{lag}'] = combined_df.groupby(['System', 'River'])[feat].shift(lag)\n",
    "\n",
    "    combined_df = combined_df.dropna(axis=1, how='any').dropna()\n",
    "\n",
    "    train_df, test_df = split_time_series_by_river(\n",
    "        combined_df,\n",
    "        time_column=\"Year\",\n",
    "        group_columns=[\"System\", \"River\"],\n",
    "        test_fraction=0.2,\n",
    "        gap_years=0\n",
    "    )\n",
    "\n",
    "    train_df[\"River_Name\"] = train_df[\"River\"]\n",
    "    test_df[\"River_Name\"] = test_df[\"River\"]\n",
    "\n",
    "    train_df_encoded = pd.get_dummies(train_df, columns=[\"River\"], prefix=\"River\")\n",
    "    test_df_encoded = pd.get_dummies(test_df, columns=[\"River\"], prefix=\"River\")\n",
    "\n",
    "    for model_name in model_list:\n",
    "        try:\n",
    "            results = train_and_apply_rf_with_tuning(\n",
    "                model=model_name,\n",
    "                train_df=train_df_encoded,\n",
    "                test_df=test_df_encoded,\n",
    "                topk_feat=top_k_features\n",
    "            )\n",
    "\n",
    "            # âœ… Apply ARIMA correction if selected\n",
    "            if use_arima_on_top:\n",
    "                residuals = results[\"Timeline_train\"][\"Actual\"] - results[\"Timeline_train\"][\"Predicted\"]\n",
    "                residuals_series = pd.Series(residuals.values, index=results[\"Timeline_train\"][\"Year\"])\n",
    "\n",
    "                arima_model = ARIMA(residuals_series, order=(1, 0, 0))\n",
    "                arima_fit = arima_model.fit()\n",
    "\n",
    "                residual_forecast = arima_fit.forecast(steps=len(results[\"Timeline_test\"][\"Predicted\"]))\n",
    "                hybrid_pred = results[\"Timeline_test\"][\"Predicted\"] + residual_forecast.values\n",
    "\n",
    "                results[\"Timeline_test\"][\"Predicted\"] = hybrid_pred\n",
    "\n",
    "                # Optionally update metrics\n",
    "                r2 = r2_score(results[\"Timeline_test\"][\"Actual\"], hybrid_pred)\n",
    "                mse = mean_squared_error(results[\"Timeline_test\"][\"Actual\"], hybrid_pred)\n",
    "                mape = mean_absolute_percentage_error(results[\"Timeline_test\"][\"Actual\"], hybrid_pred) * 100\n",
    "\n",
    "                # Also update metrics per river (recalculate)\n",
    "                grouped = results[\"Timeline_test\"].groupby(\"River_Name\")\n",
    "                metrics_by_river_test = grouped.apply(\n",
    "                    lambda g: pd.Series({\n",
    "                        \"R2\": r2_score(g[\"Actual\"], g[\"Predicted\"]),\n",
    "                        \"MSE\": mean_squared_error(g[\"Actual\"], g[\"Predicted\"]),\n",
    "                        \"MAPE\": mean_absolute_percentage_error(g[\"Actual\"], g[\"Predicted\"]) * 100\n",
    "                    })\n",
    "                ).reset_index()\n",
    "\n",
    "                results[\"Metrics_by_River_Test\"] = metrics_by_river_test\n",
    "\n",
    "            # ðŸ“Š Prepare final output\n",
    "            test_df_ = results['Metrics_by_River_Test'].copy()\n",
    "            train_df_ = results['Metrics_by_River_Train'].copy()\n",
    "\n",
    "            test_df_ = test_df_.rename(columns={\"R2\": \"R2_Test\", \"MSE\": \"MSE_Test\", \"MAPE\": \"MAPE_Test\"})\n",
    "            train_df_ = train_df_.rename(columns={\"R2\": \"R2_Train\", \"MSE\": \"MSE_Train\", \"MAPE\": \"MAPE_Train\"})\n",
    "\n",
    "            merged_df = pd.merge(test_df_, train_df_, on=\"River_Name\", how=\"outer\")\n",
    "            merged_df.insert(0, \"Model\", model_name)\n",
    "\n",
    "            river_system_lookup = pd.concat([train_df_encoded, test_df_encoded])[\"River_Name\"].drop_duplicates()\n",
    "            river_system_lookup = pd.merge(\n",
    "                river_system_lookup.to_frame(),\n",
    "                combined_df[[\"River\", \"System\"]].drop_duplicates(),\n",
    "                left_on=\"River_Name\",\n",
    "                right_on=\"River\",\n",
    "                how=\"left\"\n",
    "            ).drop(columns=\"River\")\n",
    "\n",
    "            merged_df = pd.merge(merged_df, river_system_lookup, on=\"River_Name\", how=\"left\")\n",
    "\n",
    "            merged_df[\"Selected_System\"] = river_system\n",
    "            merged_df[\"TopK_Features\"] = top_k_features\n",
    "            merged_df[\"Additional_Features_Used\"] = add_additional_features\n",
    "            merged_df[\"ARIMA_Enabled\"] = use_arima_on_top\n",
    "\n",
    "            all_experiments.append(merged_df)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error with model {model_name}: {e}\")\n",
    "\n",
    "# ðŸ“ Save final results\n",
    "final_df = pd.concat(all_experiments, ignore_index=True)\n",
    "output_path = r\"C:\\Users\\MuriloFarias\\Desktop\\NNS-JULIA\\PredictSalmonRuns\\murilo_salmon\\julia_models\\results.csv\"\n",
    "final_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\nâœ… All experiment results saved to:\\n{output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c82e4e",
   "metadata": {},
   "source": [
    "### Optional: Fit ARIMA model on residuals (only works if only one river selected so far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b2fd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:    \n",
    "    residuals = results[\"Timeline_train\"][\"Actual\"] - results[\"Timeline_train\"][\"Predicted\"]\n",
    "\n",
    "    from statsmodels.tsa.arima.model import ARIMA\n",
    "    residuals_series = pd.Series(residuals.values, index=results[\"Timeline_train\"][\"Year\"])\n",
    "    arima_model = ARIMA(residuals_series, order=(1,0,0))  # You may want to auto-tune this\n",
    "    arima_fit = arima_model.fit()\n",
    "    residual_forecast = arima_fit.forecast(steps=len(results[\"Timeline_test\"][\"Predicted\"]))\n",
    "\n",
    "    hybrid_pred = results[\"Timeline_test\"][\"Predicted\"] + residual_forecast.values\n",
    "    from sklearn.metrics import mean_squared_error, r2_score\n",
    "    r2 = r2_score(results[\"Timeline_test\"][\"Actual\"], hybrid_pred)\n",
    "    print(r2)\n",
    "\n",
    "    results[\"Timeline_test\"][\"Predicted\"] = hybrid_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d13d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_items = sorted(results[\"Feature_Importances\"].items(), key=lambda x: x[1], reverse=True)\n",
    "features, importances = zip(*sorted_items)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(features, importances, color='skyblue')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Feature Importances')\n",
    "plt.gca().invert_yaxis()  # Most important on top\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
